#!/usr/bin/env node
var R=Object.defineProperty;var r=(e,t)=>R(e,"name",{value:t,configurable:!0});import{Command as T}from"@commander-js/extra-typings";import{glob as S}from"glob";import{readFile as d,writeFile as U,access as D,mkdir as q}from"node:fs/promises";import{resolve as C}from"node:path";import L from"path";import h from"chalk";import M from"spinnies";import{randomUUID as E}from"node:crypto";import G from"openai";import $ from"yaml";async function F(e,t,o="File"){let n=null,i="";if(e)try{i=C(e),n=await d(i,{encoding:"utf-8"})}catch{throw new Error(`${o} not found, see --help for details`)}else{for(const c of t.formats)try{i=C(t.name+"."+c),n=await d(i,{encoding:"utf-8"});break}catch{continue}if(n===null)throw new Error(`${o} not found, see --help for details`)}return{content:n,format:i.split(".").pop()??""}}r(F,"loadFile");function W(e,t){e=e.replace("**/*","**");const o=/(?<asterisks>\*{1,2})(?<extension>\.[^\\/]+)?/,n=e.match(o);if(n){let i="";return n.groups?.asterisks.length==1?i+=t.fileNameStem:i+=t.directoryPath+t.fileNameStem,n.groups?.extension?i+=n.groups.extension:i+=t.fileExtension,e.replace(n[0],i)}return e}r(W,"replaceFilePattern");function H(e){const t=/(?<name>[^\\/]+)(?<extension>\.[^\\/]+)$/,o=e.match(t);return o&&o.length>0&&o.groups?{absolutePath:e,directoryPath:e.replace(o[0],""),fileExtension:o.groups.extension,fileNameStem:o.groups.name,fullFileName:o[0]}:null}r(H,"pathToComponents");async function K(e,t="."){try{return(await S(`${t}/${e}.*`)).length>0}catch{return!1}}r(K,"fileExists");async function I(e){const t=L.dirname(e);try{await D(t)}catch{await I(t),await q(t)}}r(I,"ensureDirectoryExistence");async function Y(e,t){await I(e),await U(e,t)}r(Y,"writeFileWithDirectories");function m(e){return Array.isArray(e)?e:[e]}r(m,"arrayify");function b(e){return typeof e=="string"?e:JSON.stringify(e,null,2)}r(b,"stringify");function k(e){return e.slice(0,8)}r(k,"friendly");class z{static{r(this,"Logger")}spinnies=new M({color:"white",succeedColor:"white"});opts={debug:!1};setOptions(t){this.opts={debug:t.debug??!1}}get progress(){return{add:r((t,o)=>{this.spinnies.add(t,{text:o})},"add"),update:r((t,o)=>{this.spinnies.update(t,{text:o})},"update"),succeed:r((t,o)=>{this.spinnies.succeed(t,{text:o})},"succeed"),fail:r((t,o)=>{this.spinnies.fail(t,{text:o})},"fail")}}get info(){return{group(t){console.log(`
${h.blue("==>")} ${h.whiteBright.bold(b(t))}`)},log:r(t=>console.log(b(t)),"log")}}get debug(){if(this.opts.debug)return{group(t){console.log(`
${h.gray("==>")} Debug: ${b(t)}`)},log:r(t=>console.log(h.gray(b(t))),"log")}}}const s=new z;async function N(e,t,o={}){return new Q(e,t,o)}r(N,"getAgentCommand");class Q{static{r(this,"AgentJob")}type="agent";id;job;provider;variables;constructor(t,o,n={}){this.id=E(),this.job=t,this.provider=o,this.variables=n}async execute(t,o){const{job:n,provider:i}=this,{steps:c}=n;s.progress.add(this.id,`[${k(this.id)}] Starting job`);const a=[];for(const[f,l]of c.entries())if(s.progress.update(this.id,`[${k(this.id)}] Processing step ${f}: ${l.role}`),l.role==="system")a.push({role:l.role,content:l.content});else if(l.role==="user"){const g=await this.processInput(l);a.push({role:l.role,content:g});const p=await i.createChatCompletionRequest(a).execute();o.in+=p.usage.in,o.out+=p.usage.out;const v=await this.handleResponse(l,p),{action:A,message:O,error:B}=v;if(A=="error"){console.error(B);break}A=="continue"&&O&&a.push(O)}s.progress.succeed(this.id,`[${k(this.id)}] complete`)}async processInput(t){let o=t.content;if(t.replace){const n=m(t.replace);for(const i of n){const c=i.source??"variables";if(c==="variables")o=o.replace(i.pattern,this.variables[i.name]);else if(c==="file")try{const a=await d(i.name,"utf-8");o=o.replace(i.pattern,a)}catch(a){console.error(a)}}}return o}async handleResponse(t,o){if(o.type=="success")switch(o.reason){case"stop":return await this.processResponse(t,o.message.content??""),{action:"continue",message:o.message};case"length":return{action:"error",message:o.message,error:new Error("Incomplete model output due to `max_tokens` parameter or token limit")};case"function_call":default:return{action:"error",message:o.message,error:new Error("Incomplete model output due to `max_tokens` parameter or token limit")}}return{action:"error",error:new Error("Failed to get response from AI provider")}}async processResponse(t,o){const n=m(t.response??[]);for(const i of n)if(i.action==="write-to-disk"){const c=i.output,a=W(c,this.variables.file);await Y(a,o)}else i.action==="save-to-variables"?this.variables[i.output]=o:s.debug?.log("No post action to take")}}async function V(e,t,o){const n=new X(e,t);return await n.setup(o),n}r(V,"getBatchCommand");class X{static{r(this,"BatchCommand")}id;job;provider;runs=[];constructor(t,o){this.id=E(),this.job=t,this.provider=o}async setup(t){if(!this.job.batch)throw new Error("Batch job is missing batch field");const o=m(this.job.batch);for(const n of o)if(n.type==="files"){const i=n.input,c=await S(i,{withFileTypes:!0});for(const a of c){const f=a.fullpath(),l=H(f);if(!await Z(n["skip-condition"],l)){const p={variables:{content:await d(f,"utf-8"),file:l},job:this.job};this.runs.push(p)}}}}async execute(t,o){const n=[],i=[];if(this.runs.length==0)return Promise.resolve("No runs to execute.").then(()=>{s.info.log("No runs to execute")});let c=0;s.progress.add(this.id,`Working on 0/${this.runs.length}`);for(let a=0;a<this.runs.length;a++){const f=this.runs[a],l=new Promise(async(g,w)=>{const p=await N(f.job,this.provider,f.variables);try{await p.execute(t,o),g()}catch(v){console.error(v),w()}finally{c+=1,s.progress.add(this.id,`Working on ${c}/${this.runs.length}`)}});n.push(l),i.push(l),i.length>=5&&(await Promise.all(i),i.length=0)}return Promise.all(n).then(()=>{s.progress.succeed(this.id,`All jobs (${this.runs.length}) completed`)})}}async function Z(e,t){if(e){let o=m(e);for(const n of o)if(n.folder&&n.contains&&n.contains==="fileNameStem"&&t)return await K(t.fileNameStem,n.folder)}return!1}r(Z,"processSkipRules");class ee{static{r(this,"OpenAIProvider")}name="OpenAI";openai;model;constructor(t,o,n){this.model=t,this.openai=new G({apiKey:o.providers.openai["api-key"]})}createChatCompletionRequest(t){return new te(this.openai,this.model,t)}}class te{static{r(this,"OpenAIRequest")}messages={};openai;model;constructor(t,o,n){this.openai=t,this.model=o||"gpt-4o",this.messages=n}async execute(){return new Promise(async(o,n)=>{const i=this.messages,c=await this.openai.chat.completions.create({model:this.model,messages:i}),a=oe(c);o(a)})}}function oe(e){const t=e.choices[0];return{type:"success",id:e.id,model:e.model,reason:t.finish_reason,message:{content:t.message.content,role:t.message.role},usage:{in:e.usage?.prompt_tokens??0,out:e.usage?.completion_tokens??0},raw:e}}r(oe,"translate");function se(e,t,o){return e.engine=="openai"?new ee(e.model,t,o):null}r(se,"getEngine");const ne="ax.config",ie=["yaml","yml","json"];async function re(e,t){const{content:o,format:n}=await F(e,{name:ne,formats:ie},"Config File");let i=null;if(n==="json")i=JSON.parse(o);else if(n==="yaml"||n==="yml")i=$.parse(o);else throw new Error("Invalid config file format");if(s.debug?.group("The Config Object"),s.debug?.log(i),ae(i))return i;throw new Error("The config file is not valid")}r(re,"getConfig");function ae(e){return e&&typeof e=="object"&&"providers"in e&&typeof e.providers=="object"&&Object.keys(e.providers).length>0&&Object.entries(e.providers).every(([t,o])=>typeof t=="string"&&o&&typeof o=="object"&&"api-key"in o&&typeof o["api-key"]=="string"&&(!("model"in o)||typeof o.model=="string"))}r(ae,"isConfig");const ce="ax.job",le=["yaml","yml","json"];async function ue(e,t){const{content:o,format:n}=await F(e,{name:ce,formats:le},"Job File");let i=null;if(n==="json")i=JSON.parse(o);else if(n==="yaml"||n==="yml")i=$.parse(o);else throw new Error("Invalid job file format");if(s.debug?.group("The Job Object"),s.debug?.log(i),fe(i))return i;throw new Error("The job file is not valid")}r(ue,"getJob");function fe(e){if(!e||typeof e!="object")return s.debug?.log("isJobConfig: obj is not an object"),!1;if(!pe(e.using))return s.debug?.log("isJobConfig: using property is invalid"),!1;if(typeof e.jobs!="object")return s.debug?.log("isJobConfig: jobs is not an object"),!1;for(const t of Object.values(e.jobs))if(!P(t))return s.debug?.log("isJobConfig: invalid job in jobs object"),!1;return!0}r(fe,"isJobConfig");function pe(e){return!e||typeof e!="object"?(s.debug?.log("isUsing: obj is not an object"),!1):e.engine!=="openai"&&e.engine!=="anthropic"?(s.debug?.log("isUsing: invalid engine"),!1):e.model!==void 0&&typeof e.model!="string"?(s.debug?.log("isUsing: model is defined but not a string"),!1):!0}r(pe,"isUsing");function P(e){if(!e||typeof e!="object")return s.debug?.log("isJob: obj is not an object"),!1;if(e.type!=="agent"&&e.type!=="batch")return s.debug?.log("isJob: invalid job type"),!1;if(!Array.isArray(e.steps))return s.debug?.log("isJob: steps is not an array"),!1;for(const t of e.steps)if(!he(t))return s.debug?.log("isJob: invalid step in steps array"),!1;return!0}r(P,"isJob");function ge(e){return!e||typeof e!="object"?(s.debug?.log("isSkipOptions: obj is not an object"),!1):typeof e.folder!="string"?(s.debug?.log("isSkipOptions: folder is not a string"),!1):typeof e.contains!="string"?(s.debug?.log("isSkipOptions: contains is not a string"),!1):!0}r(ge,"isSkipOptions");function de(e){if(!P(e))return s.debug?.log("isBatchJob: obj is not a valid Job"),!1;if(e=e,e.type!=="batch")return s.debug?.log("isBatchJob: job type is not 'batch'"),!1;if(!Array.isArray(e.batch))return s.debug?.log("isBatchJob: batch is not an array"),!1;for(const t of e.batch){if(t.type!=="files")return s.debug?.log("isBatchJob: batch item type is not 'files'"),!1;if(typeof t.input!="string")return s.debug?.log("isBatchJob: input is not a string"),!1;if(t["skip-condition"]!==void 0){if(!Array.isArray(t["skip-condition"]))return s.debug?.log("isBatchJob: skip-condition is not an array"),!1;for(const o of t["skip-condition"])if(!ge(o))return s.debug?.log("isBatchJob: invalid skip-condition"),!1}}return!0}r(de,"isBatchJob");function he(e){return!e||typeof e!="object"?(s.debug?.log("isStep: obj is not an object"),!1):e.role!=="system"&&e.role!=="user"?(s.debug?.log("isStep: invalid step type"),!1):typeof e.content!="string"?(s.debug?.log("isStep: message is not a string"),!1):e.response!==void 0&&typeof e.response!="object"?(s.debug?.log("isStep: response property is missing"),!1):e.replace!==void 0&&typeof e.replace!="object"?(s.debug?.log("isStep: replace is defined but not an object"),!1):!0}r(he,"isStep");const x=new T().version("1.0.0").option("--dry-run","Run the application without executing against the AI providers").option("-c, --config <path>","Path to the config file").option("-j, --job <path>","Path to the job file").option("-d, --debug","Print additional debug information");x.parse();const u=x.opts();s.setOptions(u),u.debug&&(s.debug?.group("Options"),s.debug?.log(u));let _,j;try{_=await re(u.config??null,u),j=await ue(u.job??null,u)}catch(e){console.error(`${e}`),x.outputHelp(),process.exit(1)}const J=se(j.using,_,u);J||(console.error("AI Provider is not defined. Please check your job file."),process.exit(1)),s.info.group("All systems operational. Running job..."),u.dryRun&&s.info.log("Dry run mode enabled. No API calls will be made.");const y={in:0,out:0};for(const[e,t]of Object.entries(j.jobs))s.info.group(`Executing "${e}"`),de(t)?await(await V(t,J,u)).execute(u,y):await(await N(t,J)).execute(u,y);s.info.group("Usage"),s.info.log(`Input tokens: ${y.in} `),s.info.log(`Output tokens: ${y.out} `),s.info.group("Complete. Goodbye");
